% Copyright 2021 Jacopo Maltagliati
%
% Use of this source code is governed by an EUPL-style
% license that can be found in the LICENSE file or at
% https://eupl.eu/1.2/en/.
% A localized copy of this license can be found in the LICENSE.it file or at
% https://eupl.eu/1.2/it/
%
% Portions of this document are subject to different licensing agreements,
% see src/titlepage.tex for details.

\documentclass[a4paper,12pt]{report}
\usepackage[paper=a4paper,margin=1in]{geometry}
\usepackage{graphicx}
%\usepackage{hyperref}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
\usepackage{setspace}
\usepackage[english]{babel}
%\usepackage{amssymb}
%\usepackage{amsthm}
%\usepackage{amsmath}
%\usepackage{amstext}
\usepackage{microtype}
\usepackage{csquotes}
\usepackage{bookmark}
\usepackage{xpatch}
\usepackage{listings}
\usepackage[backend=biber, sorting=none]{biblatex}
\hypersetup{colorlinks=true, linkcolor=blue, citecolor=blue, urlcolor=blue, pdftitle={Linux as a Real-Time Operating System}}
\addbibresource{all.bib}
\usepackage[color=green,textsize=tiny]{todonotes}
\usepackage{sectsty}
\chapternumberfont{\large}
\chaptertitlefont{\huge}
\renewcommand{\familydefault}{\sfdefault}
\begin{document}
% Titlepage
\input{titlepage.tex}
\newpage
% Quote
\vspace*{\stretch{1}}
\begin{flushright}
  \itshape
  \begin{tabular}{@{}l@{}}
    In Fulvio Testi 175 we trust \\
    2017-2020
  \end{tabular}
\end{flushright}
\vspace{\stretch{2}}
\newpage
% Toc
\tableofcontents
\newpage
% Ch0
\chapter*{Acknowledgements}
A special thanks for the continued support and previous work on Otto, ROS and the USAD platform goes to the IRAlab team:
Simone Fontana
Federica di Lauro
Carlo Radice 
Giovanni Capra
Riccardo Curnis
And to the former IRAlab member:
Augusto Luis Ballardini

% Ch1
\chapter{Summary}

In the past ten years, mobile robotics as a field has been gaining a lot of traction: as technology evolves, building a mobile platform has become more and more feasible for anyone, including small research teams and hobbyists. However, there is still a lack of easily approachable real-time solutions able to manage the workload, as many of the available frameworks are not mature enough to offer fine-grained real time application control: this is why we ultimately decided to push the Linux kernel to its limits, studying its real-time capabilities and ease of use.

\section{The problem}

Imagine driving on an empty road at night while listening to classical music: it's been a very long day, and your consciousness gradually drifts to a peaceful slumber. Suddenly, an animal crosses the road: are you going to notice? Will you be able to stop in time? Now, consider a self-driving car in the same situation: what would happen if the control computer "dozed off" even for a fraction of a second? The user would probably not be able to stomp on the brakes fast enough to prevent the car from crashing.

A possible solution to this problem is carefully designing a system built around existing technologies, such as real-time control, redundant hardware platforms, and failsafe mechanisms. However, creating a real-time system from the ground up tends to be very expensive and error-prone, as incorrect design or minor mistakes could lead to catastrophic failures such as the infamous Therac\cite{therac-25-accidents} incidents.

For this reason, many software houses have been working on various commercial solutions since the 1980s that enabled programmers and engineers to deploy their application on proven grounds, thus reducing the time and effort needed to create a real-time application. Arguably, the best aspect of those systems was their widespread availability: for example, DEC's VAXeln used lightly modified VAX computers, and Quantum Computer Inc. QNX ran on consumer-grade hardware, including x86 processors. While the VAXeln is now a historical platform, QNX is still commercially available from BlackBerry Inc. and major companies such as Apple use it for their products\cite{time-carplay-qnx}.

However, having always demonstrated an incredible flexibility, the ubiquitous Linux kernel is becoming a viable option for robotics and real-time usage, with both academic and commercial applications exploiting it like Tesla Motors, which maintains its own fork\cite{gh-tesla-linux}.

Of course, this flexibility comes at the cost of reduced effectiveness in each specific situation, so why do both academic and commercial researchers decide to use Linux? For example:
\begin{itemize}
  \item Linux is free and comes at no cost.
  \item Linux is open-source, so it might be tailored to specific needs
        with the right expertise.
  \item Linux has a wide community of people constantly improving it,
        ensuring constant updates without any support contract.
\end{itemize}

These, along with the fact that IRAlab has been running Linux on control systems for several years, are the reasons why we decided to adopt it for this project.

\section{Current Implementation}

At the moment, most of IRAlab's mobile platforms are controlled by a master node running Ubuntu Linux 16.04 LTS and the ROS framework. The ROS (Robot Operating System) framework is an open-source middleware, that is a set of software libraries and tools that help you build robot applications. ROS was created by Willow Garage as a rapid development platform for their PR2 robot and traces its roots into an even earlier effort by a team of researchers and students at Stanford University.

Despite its name, ROS needs a host operating system, which can be either Linux, Windows or macOS. For simplicity, throughout this report we'll focus only on the ROS/Linux combination.

\subsection{Description}

Currently, IRAlab mainly uses a modified ROS navigation stack for abstraction and rapid prototyping: through the use of \textit{topics} and \textit{messages}, ROS provides a facility to let the users write small programs, called \textit{nodes}, and make them communicate with each other. A \textit{master node}, provided by the framework, acts as a central hub, keeping tabs on the state of the \textit{Computational Graph}. Moreover, ROS provides extensive \textit{timestamping} and data logging facilities, letting the user easily track, monitor and simulate a mobile platform's behavior.

An in-depth analysis of the ROS functionalities and usage in the context of our mobile platforms is beyond the scope of this report, but the same topic has received extensive coverage in earlier works by Gerosa* and Di Lauro\cite{fdila-bs-otto}.
%% todo dilauro -> ???

\subsection{Issues}

The problem we encountered with ROS is its complexity: while it's a easily modifiable and extensible, there is no simple way to control precisely how the nodes are scheduled. Finely tuning this behavior would imply modifying the source code extensively, which is a very complex task. The authors of the software have acknowledged those problems and set out to release a newer, real-time friendly version of the platform\cite{ros2-realtime-intro}.

Moreover, the presence of a Master node and an inter-node communication protocol based on handshaking (much akin to how MTTQ operates) makes it difficult to precisely control timing, unless the whole node setup is performed offline.

The real problem, however, comes from the fact that many any parts of ROS are written in Python, which is an interpreted (or rather JIT-compiled) language. This class of languages are notoriously hard to control in real-time environments, because they are not designed with real-time constraints in mind and employ facilities like non-deterministic garbage collection and dynamic allocation that could be avoided entirely by using a compiled language such as C. Explaining how the Python garbage collector works is beyond the scope of this report, but a cursory introduction is provided by the Python Developer's Guide\cite{python-devguide-gc}.

\section{Possible Solutions}

To achieve precise real-time control of our application we decided to explore the capabilities of the RT patch, which greatly reduces the latency of the Linux kernel, thus giving the programmer more control on the timing of a real-time application.

\subsection{\texttt{PREEMPT\_RT}}

%% brief history of p-rt: who's behind it?
\texttt{PREEMPT\_RT} is a patch for the Linux kernel introduced in 2005 with the goal of reducing the latency and increasing the determinism of the kernel. The patch was not immediately recognized by the Linux kernel developers, but it's slowly gained traction and it's hopefully going to be merged into mainline soon.\cite{lwn-rt-future}

%% how does preempt-rt work?
Over the course of the last 16 years, many features that help the kernel behave in a more real-time way have trickled down from the RT patch to the mainline. Some notable examples are:

%% todo
\begin{itemize}
    \item The removal of spinlocks
    \item The introduction of Threaded Interrupt Handlers
\end{itemize}

A proper analysis of the Real-Time patch has been performed by Rezenghani et al.\cite{survey-preempt-rt}.

%% how can we determine the benefits of preempt-rt?
The benefits of \texttt{PREEMPT\_RT}  are invaluable: at the cost of throughput, unbounded latencies are virtually eliminated and the performance benefits are notable *%% todo: cite

It's important to note that, while \texttt{PREEMPT\_RT} has some competition in the real-time Linux market, it's the only solution that does not involve a co-kernel approach: this ensures that any program written and compiled for mainline Linux will run unmodified on a kernel patched with \texttt{PREEMPT\_RT}, while benefiting from the various improvements brought on by the patch. 

\subsection{ROS2}

%% TODO check ros2 toy and release
ROS version 2 is the new generation of the ROS platform, which at the time of writing has been undergoing development since 20xx and is now at release x.

%% what are the benefits of using ros2?
ROS2 has been designed with real time constraints in mind to solve the shortcomings of ROS, as it pipelines tasks in a very different way and uses an enterprise-grade communications subsystem that is much more RT-friendly. ROS2 uses a single process to control and schedule tasks, spawning them as threads.

%% why would keeping ros be important?
Keeping ROS would've enabled us to benefit from real-time improvements without the burden of porting the whole application stack to a new platform, thus reducing turnaround time significantly. 

%% why did we rule out ros2 entirely?
In the end, we decided that ROS2 would not give us precise enough control on RT constraints because since the tasks are scheduled by an algorithm internal to ros2*<ros2 internals>, it's impossible for us to schedule single tasks with an RT-scheduler provided by Linux such as RT or EDF. 

\subsection{\texttt{SCHED\_EDF}}

%% brief history of sched-edf and who's behind it
SCHED\_EDF is a scheduler developed by <! inserire nomi qui> that's been available since Kernel <!versione linux qui>. The EDF scheduler allows the programmer to define and schedule tasks in the highest possible scheduling class <vedi capitolo classi scheduling> with an Earlier Deadline First" algorithm. The programmer must define:

\begin{itemize}
    \item A period, that is the time after which the task repeats itself (or rather the scheduler does)
    \item A deadline, that is the time after which the task has taken too long to complete
    \item A runtime, that is the WCET of the task
\end{itemize}

The CBS algorithm is used in conjunction with EDF for...
\todo{Dig up details about CBS}

%% how does sched-edf work
The algorithms behind SCHED\_EDF are described by *<abeni, buttazzo>.

%% sposta in edf
\subsubsection{Scheduling classes in Linux}

Scheduling classes in Linux are a system to provide different scheduling algorithms for different kinds of tasks while maintaining a specific hierarchy 

%% scheduling priority
The priority of the various scheduling classes is as follows:
STOP > DL > RT > CFS > IDLE > NULL

CFS replaced the older O(1) scheduler as the default scheduler in Linux 2.6.22 %%https://lwn.net/Articles/241085/
Refer to *<sched(7)>.

\newpage
% Ch2
\chapter{Solution}

Our custom solution, named \texttt{rt-app}, is a demonstration of what we believe is a viable approach for building real-time control systems on Linux.

Written from scratch, the demo currently leverages several APIs provided by Linux such as \texttt{sched}, \texttt{time} and \texttt{pthreads}.

\section{Design}

\texttt{rt-app}'s design is based around some components which are regarded as 
standard in the mobile robotics field, such as:
\begin{itemize}
  \item The local planner: a component responsible for tracking
  \item The costmap:
  \item odometry: a component that constantly elaborates the data received from various sources, such as the move base's wheel encoders, to keep track of where the robot is going.
\end{itemize}

Moreover, the following components have been envisioned:
\begin{itemize}
  \item The pose manager, which is a pivotal component that manages the lifecycle of a pose, its duty is to control the flow of poses going from odometry to the local planner and backfeed adjusted poses coming from AMCL.
  \item The dispatcher, which takes care of initializing threads and resources, and is responsible for terminating the application once all workers have finished their job.
\end{itemize}

Most of these operations are to be performed on-line, that is in a real-time fashion, except for global planning and thread dispatching, both of which happen once, when the dispatcher sets the modules up.

\subsection{Rationale}

The main goal behind \texttt{rt-app}, however, is demonstrating that replicating a ROS-like behavior is possible by only using facilities provided by the Linux kernel and the GNU standard library: thus, in the following sections we'll focus more on the implementation rather than the design process.

\subsection{Planning}

Given that the work required to implement such a complex application can't be possibly condensed in such a short timeframe, we've settled for splitting the work in several phases:
\begin{itemize}
  \item Phase 1: High level design and survey of the possible solutions
  \item Phase 2: Implementation of the dispatcher, at least one of the modules and integration with an existing mobile platform.
  \item Phase 3: Maintenance and gradual addition of more modules, according to the programming guidelines and general architecture set by the work performed in phase 2.
\end{itemize}

Thus far, Phase 1 and a consistent portion of Phase 2 have been completed: the Odometry module has been implemented, on top of a simple dispatcher based on \texttt{pthreads} and \texttt{SCHED\_EDF}. IRAlab's Otto\cite{fdila-bs-otto} mobile platform has been selected to be the test candidate, thus the Odometry module has been interfaced with a the microcontroller that is responsible for driving Otto's motors and encoders through the serial port.

\section{Implementation}

\subsection{Components}

Three distinct types of logic components have been devised:
\begin{itemize}
    \item Modules: comprised of both a header and a source file, the modules contain the schedulable units of the application. Each module contains at least an entry point function, which will be executed when scheduling, and a number of other functions necessary to perform one or more specific tasks.   
    \item Helpers: headers that provide inline functions that wrap around system calls and kernel facilities in a standard way.
    \item Adapters: portions of code that provide an high-level interface to an hardware platform like Otto.
\end{itemize}

The only exceptions to this rule are the \texttt{main.c} file, which provides a scheduling facility, and the \texttt{config.h} file, which contains preprocessor definitions used to change the behavior of the application for debugging purposes.

\subsection{Threads and scheduling}

Each module contains a schedulable unit, a portion of code that is capable of running in a separate thread, and a number of scheduling parameters that will be passed to a \texttt{sched\_setattr()} call to modify the scheduling attributes of the module's thread.

This architecture is flexible because it lets the programmer decide how a specific module will be scheduled by the system, and using which scheduler. When using \texttt{SCHED\_DEADLINE}, for example, the programmer can provide a \textit{deadline}, a \textit{runtime} and a \textit{period}: those parameters will be used to control when the thread will be selected for execution and after which amount of time it's expected to terminate (at worst) by the scheduler.

\subsection{Timing}

As usual with systems interacting with hardware sensors, timing is a critical part of our demonstration: a simple timing system, wrapping the \texttt{clock\_*()} family of system calls, has been implemented to readily provide information such as global time deltas in nanoseconds that can be used to consistently timestamp information coming from the adapters. This collection of inline functions and globals is an helper, and resides into the \texttt{h\_time.h} header. 

To keep track of the time, the Intel x86\_64 (AMD64) architecture provides access to a series of hardware clocks via the \texttt{RDTSC} and \texttt{RDTSCP} instructions. These instructions allow the kernel to query the \texttt{TSC} (Time Stamp Counter) internal register to provide us with a reliable hardware time source. However, the \texttt{TSC} register was introduced with the Pentium architecture and with the advent of technologies like out-of-order execution, hybernation, and multi-core processing it is not advisable to rely on it anymore. This problem, and a number of possible solutions, have been discussed both in official documentation\cite{intel-rdtsc-bench} and articles from notable sources\cite{ms-rdtsc-issues}.

Conveniently, the Linux kernel works around this problem for us: to accurately advance its internal timers the kernel uses several clock sources and an unit of measurement called \textit{jiffy}, which is tied to the value of `HZ` and is fine-tuned to each architecture's needs\cite{elinux-hrts}. Thanks to this complex architecture, which is described in depth by the manual pages\cite{man-clock-getres-2}, we can trust the values provided by system calls such as \texttt{clock\_gettime()} because they're consistent enough to provide us usable values in the tens of nanoseconds range.

Besides keeping a time base and calculating deltas, the \texttt{h\_time} helper mostly performs conversions: since the standard library uses \texttt{timespec} structures to pass values around, \texttt{h\_time} is also responsible for translating \texttt{timespec}s to nanoseconds where needed.  

\subsection{Communications}

As we stated earlier, the \textit{adapters} provide a clean way to interact with various peripherals.

\subsubsection{Serial}

Currently, the demo application issues command to the Otto mobile platform via and FTDI UART using serial communications at 9600 Baud. The \texttt{a\_otto} adapter provides functions that wrap around the read() and write() system calls to communicate with Otto's microcontroller over the serial line: before being sent, the data is encoded using the NanoPB library,  

\subsection{Shared memory}

Not implemented.

\section{Future Development}

\begin{itemize}
    \item More modules
    \item Better separation of tasks
    \item Code deduplication
\end{itemize}

\newpage
% Ch3
\chapter{Implementation Issues <???>}
\section{Patching and building the kernel}

http://kernel-notes.gbittencourt.net/compiling-preempt-rt/

\begin{itemize}
    \item Download https://git.kernel.org/pub/scm/linux/kernel/git/rt/linux-stable-rt.git/tag/?h=v5.4.74-rt41-rebase and untar (~900MB of sources) and cd
    \item \texttt{cp /boot/config-\$(uname -r) .config}
    \item \texttt{make olddefconfig}
    \item \texttt{make -j \$(nproc) deb-pkg}
    \item Wait ~4Hrs
    \item Install the deb pkgs and reboot
\end{itemize}

\section{Emulating the mobile platform}

Simulating IRAlab's Otto mobile platform's comms stack with an ESP8266 (NodeMCU "amica" 1.0) and
providing dummy data to \href{https://github.com/iralabdisco/rt-app}{rt-app}'s odometry module for testing. Using nanopb for comms over a serial line over USB (UART) running at 115200 baud. 

\todo{Describe otto266 better}

\section{Processor features that are detrimental to RT performance}

\begin{itemize}
    \item Caches
    \item CPU Threads (SMT)
    \item CPU Cores (SMP)
    \item Intel Management Engine (ME) and AMD Secure Platform (PSP)
    \item Power saving states, suspension, hybernation and clock boost
\end{itemize}

\section{Logging}

Logging was implemented with syslog() and it's got better performance than printf() logging, besides it can make use of system logs and be easily trackable with tools like journalctl. Refer to *<article that says that printf is worse than syslog>

\section{Filesystem}

I'm not sure I'm keeping this section as it's pretty hard to find reputable sources, but it's a nice thing to do anyway. 

\section{Notes on CPUSETS} %% maybe it's better off here?

CPUSETS solve the problem of SMP (and SMT, to some extent) by locking specific processes (as in thread groups) to a partition of the available processors (or cores).

\todo{Explain how CPUSETS work with a code example}

% Tail
\printbibliography
\end{document}




